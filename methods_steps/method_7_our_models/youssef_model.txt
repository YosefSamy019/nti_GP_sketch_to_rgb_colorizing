def SE_Block(input_tensor, reduction=16):
    filters = input_tensor.shape[-1]
    se = GlobalAveragePooling2D()(input_tensor)
    se = Dense(filters // reduction, activation='relu')(se)
    se = Dense(filters, activation='sigmoid')(se)
    se = Reshape((1, 1, filters))(se)
    return Multiply()([input_tensor, se])


def ResidualBlock(x, filters):
    shortcut = x
    x = Conv2D(filters, 3, padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(0.2)(x)
    x = Conv2D(filters, 3, padding='same')(x)
    x = BatchNormalization()(x)
    x = Add()([shortcut, x])
    x = LeakyReLU(0.2)(x)
    return x


def build_gan_model_1():
    global models_list
    NAME = 'gan_deep_v1'

    inputs = Input((IMG_W, IMG_H, 1))

    # Encoder
    e1 = Conv2D(64, 4, strides=2, padding='same')(inputs)
    e1 = LeakyReLU(0.2)(e1)

    e2 = Conv2D(128, 4, strides=2, padding='same')(e1)
    e2 = BatchNormalization()(e2)
    e2 = LeakyReLU(0.2)(e2)

    e3 = Conv2D(256, 4, strides=2, padding='same')(e2)
    e3 = BatchNormalization()(e3)
    e3 = LeakyReLU(0.2)(e3)

    e4 = Conv2D(512, 4, strides=2, padding='same')(e3)
    e4 = BatchNormalization()(e4)
    e4 = LeakyReLU(0.2)(e4)

    # Bottleneck + Residuals + SE block
    b = Conv2D(1024, 4, strides=2, padding='same')(e4)
    b = BatchNormalization()(b)
    b = Activation('relu')(b)
    for _ in range(3):
        b = ResidualBlock(b, 1024)
    b = SE_Block(b)

    # Decoder
    d1 = Conv2DTranspose(512, 4, strides=2, padding='same')(b)
    d1 = BatchNormalization()(d1)
    d1 = Dropout(0.5)(d1)
    d1 = Activation('relu')(d1)
    d1 = Concatenate()([d1, e4])

    d2 = Conv2DTranspose(256, 4, strides=2, padding='same')(d1)
    d2 = BatchNormalization()(d2)
    d2 = Dropout(0.5)(d2)
    d2 = Activation('relu')(d2)
    d2 = Concatenate()([d2, e3])

    d3 = Conv2DTranspose(128, 4, strides=2, padding='same')(d2)
    d3 = BatchNormalization()(d3)
    d3 = Activation('relu')(d3)
    d3 = Concatenate()([d3, e2])

    d4 = Conv2DTranspose(64, 4, strides=2, padding='same')(d3)
    d4 = BatchNormalization()(d4)
    d4 = Activation('relu')(d4)
    d4 = Concatenate()([d4, e1])

    d5 = Conv2DTranspose(64, 4, strides=2, padding='same')(d4)
    d5 = BatchNormalization()(d5)
    d5 = Activation('relu')(d5)

    outputs = Conv2D(3, 1, activation='tanh')(d5)

    gen_model = Model(inputs, outputs)
    gen_model.summary()

    ### --- Discriminator ---
    disc_in = Input((IMG_H, IMG_W, 3))
    d = Conv2D(64, 4, strides=2, padding='same')(disc_in)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    d = Conv2D(128, 4, strides=2, padding='same')(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    d = Conv2D(256, 4, strides=2, padding='same')(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    d = Conv2D(512, 4, strides=1, padding='same')(d)
    d = BatchNormalization()(d)
    d = LeakyReLU(0.2)(d)

    outputs = Conv2D(1, 4, strides=1, padding='same')(d)

    descrim_model = Model(disc_in, outputs)
    descrim_model.summary()

    # Entire model
    entire_input = Input(shape=(IMG_H, IMG_W, 1))
    gen_output = gen_model(entire_input)
    discrim_output = descrim_model(gen_output)

    entire_model = Model(entire_input, discrim_output)

    custom_model = CustomModel(NAME, gen_model, descrim_model)
    models_list = list(filter(lambda x: x.name != custom_model.name, models_list))
    models_list.append(custom_model)
    
build_gan_model_1()